{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import itertools\n",
    "import sys\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import checklist_fork.checklist.editor\n",
    "import checklist_fork.checklist.text_generation\n",
    "from checklist_fork.checklist.test_types import MFT, INV, DIR\n",
    "from checklist_fork.checklist.expect import Expect\n",
    "from checklist_fork.checklist.test_suite import TestSuite\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist_fork.checklist.perturb import Perturb\n",
    "\n",
    "editor = checklist_fork.checklist.editor.Editor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax for suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journalist, historian, secretary, nurse, waitress, accountant, engineer, attorney, artist, editor, architect, model, interpreter, escort, analyst, actor, actress, assistant, intern, economist, organizer, author, investigator, agent, administrator, executive, educator, investor, DJ, entrepreneur\n"
     ]
    }
   ],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "print(', '.join(professions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax for sampling different instances of the same category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Is that Sarah or Sarah on the bus?', 'Is that Julia or Julia on the bus?', 'Is that Rebecca or Rebecca on the bus?', 'Is that Peter or Peter on the bus?']\n",
      "['Is that Robert or Frances on the bus?', 'Is that Eleanor or Mary on the bus?', 'Is that Victoria or Don on the bus?', 'Is that Harriet or Stephen on the bus?']\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\n",
    "    'Is that {first_name} or {first_name} on the bus?',\n",
    "    remove_duplicates=False, \n",
    "    nsamples=4)\n",
    "print(t.data)\n",
    "\n",
    "t = editor.template(\n",
    "    'Is that {first_name1} or {first_name2} on the bus?',\n",
    "    remove_duplicates=False, \n",
    "    nsamples=4)\n",
    "print(t.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting synonyms/antonyms\n",
    "\n",
    "Can also get hypernyms, hyponyms and related words (either hyponym and hypernym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: ['knowledgeable', 'learned', 'intimate']\n",
      "Antonyms: ['knowledgeable']\n",
      "Antonyms: ['brave', 'cautious', 'fearful', 'timid']\n"
     ]
    }
   ],
   "source": [
    "a = \"knowledgeable\"\n",
    "\n",
    "e = editor.synonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "print(\"Synonyms:\", [a] + e)\n",
    "\n",
    "e = editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "print(\"Antonyms:\", [a] + e)\n",
    "\n",
    "a = \"brave\"\n",
    "e = editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "print(\"Antonyms:\", [a] + e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbation example: replacing synonyms\n",
    "\n",
    "(Not working example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-337678a40cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(question, f(question)) where f(question) replaces synonyms?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Expect 1, should be easy because it\\'s individual word changes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_and_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynonyms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_original\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Taxonomy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_questions' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def replace_pairs(pairs):\n",
    "    def replace_z(text):\n",
    "        ret = []\n",
    "        for x, y in pairs:\n",
    "            t = re.sub(r'\\b%s\\b' % x, y, text )\n",
    "            if t != text:\n",
    "                ret.append(t)\n",
    "            if y == 'smart':\n",
    "                continue\n",
    "            t = re.sub(r'\\b%s\\b' % y, x, text )\n",
    "            if t != text:\n",
    "                ret.append(t)\n",
    "        return list(set(ret))\n",
    "    return replace_z\n",
    "\n",
    "# pairing is for QQP -- each input is a pair of questions\n",
    "def apply_and_pair(fn):\n",
    "    def ret_fn(text):\n",
    "        ret = fn(text)\n",
    "        return [(text, r) for r in ret]\n",
    "    return ret_fn\n",
    "\n",
    "\n",
    "name = '(question, f(question)) where f(question) replaces synonyms?' \n",
    "desc = 'Expect 1, should be easy because it\\'s individual word changes'\n",
    "t = Perturb.perturb(list(all_questions), apply_and_pair(replace_pairs(synonyms)), nsamples=1000, keep_original=False)\n",
    "test = INV(t.data, threshold=0.1, name=name, description=desc, capability='Taxonomy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax: more elaborate slots processing in templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['brave', 'fearful', 'cautious', 'timid'], ['stupid', 'smart', 'intelligent']]\n",
      "[('How can I become more stupid?', 'How can I become less stupid?'), ('How can I become less smart?', 'How can I become more smart?'), ('How can I become more brave?', 'How can I become less brave?'), ('How can I become less fearful?', 'How can I become more fearful?'), ('How can I become more stupid?', 'How can I become less stupid?'), ('How can I become less smart?', 'How can I become more smart?'), ('How can I become more stupid?', 'How can I become less stupid?'), ('How can I become less smart?', 'How can I become more smart?')]\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "antonyms = []\n",
    "for a in [\"brave\", \"stupid\"]:\n",
    "    antonyms.append(\n",
    "        [a] + editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less']))\n",
    "print(antonyms)\n",
    "\n",
    "t = editor.template(\n",
    "    [(\n",
    "    'How can I become more {x[0]}?',\n",
    "    'How can I become less {x[0]}?',\n",
    "    ),\n",
    "    (\n",
    "    'How can I become less {x[1]}?',\n",
    "    'How can I become more {x[1]}?',\n",
    "    )],\n",
    "    unroll=True, # remove the inner lists\n",
    "    x=antonyms,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=4)\n",
    "\n",
    "print(t.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There is a a square (shape) yellow (color) sculpture in the room.', 'There is a a tiny (size) red (color) clock in the room.', 'There is a a square (shape) white (color) table in the room.', 'There is a an oval (shape) yellow (color) clock in the room.']\n"
     ]
    }
   ],
   "source": [
    "import munch\n",
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n",
    "\n",
    "\n",
    "t = editor.template(\n",
    "    'There is a {a:p.v1} ({p.p1}) {p.v2} ({p.p2}) {obj} in the room.',\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=4,\n",
    "    save=True\n",
    ")\n",
    "\n",
    "print(t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax: to consider only certain examples in the test (using Expect)\n",
    "\n",
    "E.g. below takes all questions that were considered the same in QQP and changes the names (so that they don't match anymore). It expects that predictions 1 change to 0.\n",
    "(not working example)\n",
    "\n",
    "Q: But what happens to the questions in which there is no name? For those the expectation also changes from 1 to 0 (incorrectly)? NO. The perturbation doesn't return sentences for which the perturbation doesn't apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parsed_qs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fdf99148e060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# t = Perturb.perturb(parsed_qs, wrap_apply_to_each(Perturb.change_names), nsamples=1500, first_only=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_qs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_each_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexpect_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexpect_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_orig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpect_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0morig\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Change first name in one of the questions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parsed_qs' is not defined"
     ]
    }
   ],
   "source": [
    "# t = Perturb.perturb(parsed_qs, wrap_apply_to_each(Perturb.change_names), nsamples=1500, first_only=True)\n",
    "t = Perturb.perturb(parsed_qs, change_each_wrapper(Perturb.change_names), nsamples=500, first_only=True)\n",
    "expect_fn = Expect.eq(0)\n",
    "expect_fn = Expect.slice_orig(expect_fn, lambda orig, *args: orig == 1)\n",
    "name = 'Change first name in one of the questions'\n",
    "desc = 'Take pairs that are originally predicted as duplicates, change first name in one of them and expect new prediction to be non-duplicate'\n",
    "test = DIR(**t, expect=expect_fn, name=name, description=desc, capability='NER')\n",
    "# test.run(new_pp)\n",
    "# test.summary(3)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of elaborate expectation function\n",
    "\n",
    "(Not a working example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def extract_unknown_implications(pairs, labels):\n",
    "    graph = collections.defaultdict(lambda: set())\n",
    "    ls = {}\n",
    "    for x, y in zip(pairs, labels):\n",
    "        graph[x[0]].add(x[1])\n",
    "        graph[x[1]].add(x[0])\n",
    "        t = tuple(sorted(x))\n",
    "        ls[t] = y\n",
    "\n",
    "    d = []\n",
    "    l = []\n",
    "    for x in graph:\n",
    "        if len(graph[x]) == 1:\n",
    "            continue\n",
    "        for y in graph[x]:\n",
    "            t = tuple(sorted((x, y)))\n",
    "    #         print(t, ls[t])\n",
    "        new = list(set([tuple(sorted(a)) for a in itertools.product(list(graph[x]), list(graph[x])) if a[0] != a[1]]))\n",
    "        new = [a for a in new if a not in ls]\n",
    "        for b, c in new:\n",
    "            t1 = tuple(sorted((x, b)))\n",
    "            t2 = tuple(sorted((x, c)))\n",
    "            l1 = ls[t1]\n",
    "            l2 = ls[t2]\n",
    "            if l1 + l2 == 2:\n",
    "                l3 = 1\n",
    "            elif l1 + l2 == 1:\n",
    "                l3 = 0\n",
    "            else:\n",
    "                continue\n",
    "            new_x = [(x, b), (x, c), (b, c)]\n",
    "            new_l = np.array([l1, l2, l3])\n",
    "            d.append(new_x)\n",
    "            l.append(new_l)\n",
    "    return d, l\n",
    "\n",
    "data, ls = extract_unknown_implications(qs, labels)\n",
    "\n",
    "\n",
    "def expect_triplet(xs, preds, confs, labels, meta=None):\n",
    "    if (preds[0] + preds[1]) == 2:\n",
    "        if preds[2] != 1:\n",
    "            return np.array([-3, -2, -1])\n",
    "        else:\n",
    "            return np.array([True, True, True])\n",
    "    if (preds[0] + preds[1] == 1) and preds[1] != 0:\n",
    "        if preds[1] != 0:\n",
    "            return np.array([-3, -2, -1])\n",
    "        else:\n",
    "            return np.array([True, True, True])\n",
    "    return None\n",
    "#     if preds[0] != labels[0] or preds[1] != labels[1]:\n",
    "#         return None\n",
    "#     if preds[2] == labels[2]:\n",
    "#         return np.array([True, True, True])\n",
    "#     else:\n",
    "#         return np.array([-3, -2, -1])\n",
    "expect = Expect.testcase(expect_triplet)\n",
    "\n",
    "name = 'Testing implications'\n",
    "desc = 'f(x, a) = 1 and f(x, b) = 1 => f(a, b) = 1\\nf(x, a) = 1 and f(x, b) = 0 => f(a, b) = 0\\n Only used (x, a, b) such that (x, a) and (x, b) in val dataset and (a, b) is not.\\n Expectation function filters out examples where f(x, a) or f(x, b) are incorrect'\n",
    "test = DIR(data, expect, labels=ls, name=name, description=desc, capability='Logic')\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=3)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another expect example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prediction can go up, but shouldn't do down\n",
    "monotonic_label = Expect.monotonic(increasing=True, tolerance=0.1)\n",
    "non_neutral_pred = lambda pred, *args, **kwargs: pred != 1\n",
    "monotonic_label = Expect.slice_pairwise(monotonic_label, non_neutral_pred)\n",
    "\n",
    "# the prediction can go down, but shouldn't go up\n",
    "monotonic_label_down = Expect.monotonic(increasing=False, tolerance=0.1)\n",
    "monotonic_label_down = Expect.slice_pairwise(monotonic_label_down, non_neutral_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Elaborate template\n",
    "\n",
    "It can be then fed into some function that takes the filled sentences and returns different templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'contexts': ['Kate is super happy about the project. Pamela is happy about the project.', 'Pamela is happy about the project. Kate is super happy about the project.', 'Kate is happy about the project. Pamela is a little happy about the project.', 'Pamela is a little happy about the project. Kate is happy about the project.', 'Kate is super happy about the project. Pamela is a little happy about the project.', 'Pamela is a little happy about the project. Kate is super happy about the project.'], 'qas': [('Who is most happy about the project?', 'Kate'), ('Who is least happy about the project?', 'Pamela')]}, {'contexts': ['Larry is extremely vocal about the project. Caroline is vocal about the project.', 'Caroline is vocal about the project. Larry is extremely vocal about the project.', 'Larry is vocal about the project. Caroline is somewhat vocal about the project.', 'Caroline is somewhat vocal about the project. Larry is vocal about the project.', 'Larry is extremely vocal about the project. Caroline is somewhat vocal about the project.', 'Caroline is somewhat vocal about the project. Larry is extremely vocal about the project.'], 'qas': [('Who is most vocal about the project?', 'Larry'), ('Who is least vocal about the project?', 'Caroline')]}, {'contexts': ['Eric is quite serious about the project. Keith is serious about the project.', 'Keith is serious about the project. Eric is quite serious about the project.', 'Eric is serious about the project. Keith is a little serious about the project.', 'Keith is a little serious about the project. Eric is serious about the project.', 'Eric is quite serious about the project. Keith is a little serious about the project.', 'Keith is a little serious about the project. Eric is quite serious about the project.'], 'qas': [('Who is most serious about the project?', 'Eric'), ('Who is least serious about the project?', 'Keith')]}]\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']\n",
    "\n",
    "temp_temp = editor.template(\n",
    "{\n",
    "    'contexts': [\n",
    "        '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "        '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "        '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "        '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "        '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "    ],\n",
    "    'qas': [\n",
    "        (\n",
    "            'Who is most {s} about the project?',\n",
    "            '{first_name}'\n",
    "        ), \n",
    "        (\n",
    "            'Who is least {s} about the project?',\n",
    "            '{first_name1}'\n",
    "        ), \n",
    "\n",
    "    ]\n",
    "\n",
    "},\n",
    "s = state,\n",
    "very=very,\n",
    "somewhat=somewhat,\n",
    "remove_duplicates=True,\n",
    "nsamples=3,\n",
    "save=True\n",
    ")\n",
    "\n",
    "print(temp_temp.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Harriet is super curious about the project. Sharon is curious about the project.', 'Who is most curious about the project?'), ('Harriet is super curious about the project. Sharon is curious about the project.', 'Who is least curious about the project?'), ('Sharon is curious about the project. Harriet is super curious about the project.', 'Who is most curious about the project?'), ('Sharon is curious about the project. Harriet is super curious about the project.', 'Who is least curious about the project?'), ('Harriet is curious about the project. Sharon is mildly curious about the project.', 'Who is most curious about the project?'), ('Harriet is curious about the project. Sharon is mildly curious about the project.', 'Who is least curious about the project?'), ('Sharon is mildly curious about the project. Harriet is curious about the project.', 'Who is most curious about the project?'), ('Sharon is mildly curious about the project. Harriet is curious about the project.', 'Who is least curious about the project?'), ('Harriet is super curious about the project. Sharon is mildly curious about the project.', 'Who is most curious about the project?'), ('Harriet is super curious about the project. Sharon is mildly curious about the project.', 'Who is least curious about the project?'), ('Sharon is mildly curious about the project. Harriet is super curious about the project.', 'Who is most curious about the project?'), ('Sharon is mildly curious about the project. Harriet is super curious about the project.', 'Who is least curious about the project?')], [('Stephanie is quite confident about the project. Rachel is confident about the project.', 'Who is most confident about the project?'), ('Stephanie is quite confident about the project. Rachel is confident about the project.', 'Who is least confident about the project?'), ('Rachel is confident about the project. Stephanie is quite confident about the project.', 'Who is most confident about the project?'), ('Rachel is confident about the project. Stephanie is quite confident about the project.', 'Who is least confident about the project?'), ('Stephanie is confident about the project. Rachel is a little confident about the project.', 'Who is most confident about the project?'), ('Stephanie is confident about the project. Rachel is a little confident about the project.', 'Who is least confident about the project?'), ('Rachel is a little confident about the project. Stephanie is confident about the project.', 'Who is most confident about the project?'), ('Rachel is a little confident about the project. Stephanie is confident about the project.', 'Who is least confident about the project?'), ('Stephanie is quite confident about the project. Rachel is a little confident about the project.', 'Who is most confident about the project?'), ('Stephanie is quite confident about the project. Rachel is a little confident about the project.', 'Who is least confident about the project?'), ('Rachel is a little confident about the project. Stephanie is quite confident about the project.', 'Who is most confident about the project?'), ('Rachel is a little confident about the project. Stephanie is quite confident about the project.', 'Who is least confident about the project?')], [('Frank is highly pleased about the project. Frances is pleased about the project.', 'Who is most pleased about the project?'), ('Frank is highly pleased about the project. Frances is pleased about the project.', 'Who is least pleased about the project?'), ('Frances is pleased about the project. Frank is highly pleased about the project.', 'Who is most pleased about the project?'), ('Frances is pleased about the project. Frank is highly pleased about the project.', 'Who is least pleased about the project?'), ('Frank is pleased about the project. Frances is a little pleased about the project.', 'Who is most pleased about the project?'), ('Frank is pleased about the project. Frances is a little pleased about the project.', 'Who is least pleased about the project?'), ('Frances is a little pleased about the project. Frank is pleased about the project.', 'Who is most pleased about the project?'), ('Frances is a little pleased about the project. Frank is pleased about the project.', 'Who is least pleased about the project?'), ('Frank is highly pleased about the project. Frances is a little pleased about the project.', 'Who is most pleased about the project?'), ('Frank is highly pleased about the project. Frances is a little pleased about the project.', 'Who is least pleased about the project?'), ('Frances is a little pleased about the project. Frank is highly pleased about the project.', 'Who is most pleased about the project?'), ('Frances is a little pleased about the project. Frank is highly pleased about the project.', 'Who is least pleased about the project?')]]\n"
     ]
    }
   ],
   "source": [
    "def crossproduct(t):\n",
    "    # takes the output of editor.template and does the cross product of contexts and qas\n",
    "    ret = []\n",
    "    ret_labels = []\n",
    "\n",
    "    for x in t.data:\n",
    "        cs = x['contexts']\n",
    "        qas = x['qas']\n",
    "        d = list(itertools.product(cs, qas))\n",
    "        ret.append([(x[0], x[1][0]) for x in d])\n",
    "        ret_labels.append([x[1][1] for x in d])\n",
    "    t.data = ret\n",
    "    t.labels = ret_labels\n",
    "    return t\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "\n",
    "        ]\n",
    "\n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=3,\n",
    "    save=True\n",
    "    ))\n",
    "print(t.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting labels from the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bill is not a secretary, Helen is.', 'Who is a secretary?'), ('Helen is not a secretary, Bill is.', 'Who is a secretary?'), ('Charlie is not a doctor, Emma is.', 'Who is a doctor?'), ('Emma is not a doctor, Charlie is.', 'Who is a doctor?')]\n",
      "['Helen', 'Bill', 'Emma', 'Charlie']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'expect_squad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-36455e8b9261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# NOTE THAT the labels can be a list (a label for every data case) or a single value (label which applied to all)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m test = MFT(data, expect=expect_squad, labels=labels, meta=meta, templates=t.templates,\n\u001b[0m\u001b[1;32m     25\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'M/F failure rates should be similar for different professions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Fairness'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           description='Using negation in context.')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expect_squad' is not defined"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "fewer_profs = ['doctor', 'nurse', 'secretary', 'CEO']\n",
    "t = editor.template(\n",
    "    [\n",
    "        ('{male} is not {a:prof}, {female} is.', 'Who is {a:prof}?', '{female}', 'woman', '{prof}'),\n",
    "        ('{female} is not {a:prof}, {male} is.', 'Who is {a:prof}?', '{male}', 'man', '{prof}'),\n",
    "    ],\n",
    "#     prof=professions + ['doctor'],\n",
    "    prof=fewer_profs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=2,\n",
    "    unroll=True,\n",
    "    save=True,\n",
    "    )\n",
    "data = [(d[0], d[1]) for d in t.data]\n",
    "labels = [d[2] for d in t.data]\n",
    "meta = [(d[3], d[4]) for d in t.data]\n",
    "\n",
    "print(data)\n",
    "print(labels)\n",
    "\n",
    "# NOTE THAT the labels can be a list (a label for every data case) or a single value (label which applied to all)\n",
    "\n",
    "test = MFT(data, expect=expect_squad, labels=labels, meta=meta, templates=t.templates,\n",
    "          name='M/F failure rates should be similar for different professions', capability='Fairness',\n",
    "          description='Using negation in context.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More elaborate results\n",
    "\n",
    "Note that to get those results, the tests need to have meta information passed to them (as above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fair(test):\n",
    "    c = collections.Counter(test.meta)\n",
    "    fail = collections.Counter([tuple(x) for x in np.array(test.meta)[test.fail_idxs()]])\n",
    "    profs = set()\n",
    "    for sex, prof in fail:\n",
    "        profs.add(prof)\n",
    "    prof_fail = {}\n",
    "    get_fail = lambda f:fail[f] / c[f]\n",
    "    for prof in profs:\n",
    "        fail_m = get_fail(('man', prof))\n",
    "        fail_f = get_fail(('woman', prof))\n",
    "        prof_fail[prof] = (fail_m, fail_f)\n",
    "    print('%-13s fail_men fail_women (count)' % 'profession')\n",
    "    for prof, vs in sorted(prof_fail.items(), key=lambda x:max(x[1][0], x[1][1]), reverse=True):\n",
    "        fail_m, fail_f = vs\n",
    "        print('%-13s   %.1f      %.1f     (%d)' % (prof, 100 * fail_m, 100 * fail_f, c[('man', prof)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the perturbation function can also return metadata (return Tuple[List[str], List[str]] where the 2nd list is metadata). Then when we use it in Perturb we set the meta parameter to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'change_professions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6358d7f91597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_professions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_original\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'change_professions' is not defined"
     ]
    }
   ],
   "source": [
    "ret = Perturb.perturb(data, change_professions, keep_original=True, nsamples=1, meta=True)\n",
    "print('Data')\n",
    "print(ret.data)\n",
    "print('Metadata')\n",
    "print(ret.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturb and return many options for invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_words = set(\n",
    "    ['.', 'the', 'The', ',', 'a', 'A', 'and', 'of', 'to', 'it', 'that', 'in',\n",
    "     'this', 'for',  'you', 'there', 'or', 'an', 'by', 'about', 'flight', 'my',\n",
    "     'in', 'of', 'have', 'with', 'was', 'at', 'it', 'get', 'from', 'this', 'Flight', 'plane'\n",
    "    ])\n",
    "forbidden = set(['No', 'no', 'Not', 'not', 'Nothing', 'nothing', 'without', 'but'] + pos_adj + neg_adj + pos_verb_present + pos_verb_past + neg_verb_present + neg_verb_past)\n",
    "def change_neutral(d):\n",
    "#     return d.text\n",
    "    examples = []\n",
    "    subs = []\n",
    "    words_in = [x for x in d.capitalize().split() if x in neutral_words]\n",
    "    if not words_in:\n",
    "        return None\n",
    "    for w in words_in:\n",
    "        suggestions = [x for x in editor.suggest_replace(d, w, beam_size=5, words_and_sentences=True) if x[0] not in forbidden]\n",
    "        examples.extend([x[1] for x in suggestions])\n",
    "        subs.extend(['%s -> %s' % (w, x[0]) for x in suggestions])\n",
    "    if examples:\n",
    "        idxs = np.random.choice(len(examples), min(len(examples), 10), replace=False)\n",
    "        return [examples[i] for i in idxs]\n",
    "t = Perturb.perturb(sentences, change_neutral, nsamples=500)\n",
    "test = INV(t.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending sentences + some expectation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = editor.template('I {pos_verb_present} you.').data\n",
    "positive += editor.template('You are {pos_adj}.').data\n",
    "positive += ['I would fly with you again.']\n",
    "positive.remove('You are happy.')\n",
    "\n",
    "def add_phrase_function(phrases):\n",
    "    def pert(d):\n",
    "        while d[-1].pos_ == 'PUNCT':\n",
    "            d = d[:-1]\n",
    "        d = d.text\n",
    "        ret = [d + '. ' + x for x in phrases]\n",
    "        idx = np.random.choice(len(ret), 10, replace=False)\n",
    "        ret = [ret[i] for i in idx]\n",
    "        return ret\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Why not just use monotonic? Isn't it meant for such cases?\n",
    "# I guess the following functions are more specific -- require exactly 3 classes\n",
    "# and look at the general shift prediction rather the shift with respect to\n",
    "# the original label (i.e. no need for gold label)\n",
    "# we know what becoming more positive or more negative means, while monotonic\n",
    "# is with respect to the original prediction or gold label prediction\n",
    "\n",
    "def positive_change(orig_conf, conf):\n",
    "    softmax = type(orig_conf) in [np.array, np.ndarray]\n",
    "    if not softmax or orig_conf.shape[0] != 3:\n",
    "        raise(Exception('Need prediction function to be softmax with 3 labels (negative, neutral, positive)'))\n",
    "    return orig_conf[0] - conf[0] + conf[2] - orig_conf[2]\n",
    "\n",
    "def diff_up(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    tolerance = 0.1\n",
    "    change = positive_change(orig_conf, conf)\n",
    "    if change + tolerance >= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return change + tolerance\n",
    "    \n",
    "def diff_down(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    tolerance = 0.1\n",
    "    change = positive_change(orig_conf, conf)\n",
    "    if change - tolerance <= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return -(change - tolerance)\n",
    "    \n",
    "goes_up = Expect.pairwise(diff_up)\n",
    "goes_down = Expect.pairwise(diff_down)\n",
    "\n",
    "t = Perturb.perturb(parsed_data, add_phrase_function(positive), nsamples=500)\n",
    "test = DIR(t.data, goes_up)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_btools)",
   "language": "python",
   "name": "conda_btools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
